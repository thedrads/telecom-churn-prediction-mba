# üìñ Metodologia Detalhada - Projeto Churn Telecom

## Sum√°rio

1. [Vis√£o Geral](#vis√£o-geral)
2. [Prepara√ß√£o dos Dados](#prepara√ß√£o-dos-dados)
3. [An√°lise Explorat√≥ria](#an√°lise-explorat√≥ria)
4. [Sele√ß√£o de Modelos](#sele√ß√£o-de-modelos)
5. [Valida√ß√£o Final](#valida√ß√£o-final)
6. [Interpretabilidade](#interpretabilidade)
7. [Deploy Simulado](#deploy-simulado)

---

## Vis√£o Geral

Este documento detalha a metodologia completa utilizada no projeto de predi√ß√£o de churn, seguindo o roteiro acad√™mico proposto na disciplina Fundamentos de Machine Learning.

### Ferramentas

- **Orange Data Mining 3.36+**
- **Extens√£o:** Orange3-Explain
- **Sistema:** Windows 11

### Pipeline Geral

```
Dados Brutos ‚Üí Prepara√ß√£o ‚Üí An√°lise ‚Üí Modelagem ‚Üí Valida√ß√£o ‚Üí Interpreta√ß√£o ‚Üí Deploy
```

---

## Prepara√ß√£o dos Dados

### 1. Carregamento

**Widget utilizado:** File

**Arquivo:** `telecom_churn_complete.xlsx` (fornecido pelo professor)

**Estrutura:**
- Linhas: Clientes da operadora de telecom
- Colunas: 11 (10 features + 1 target)

### 2. Defini√ß√£o da Target

**Widget utilizado:** Select Columns

**Configura√ß√£o:**
- Target: `churn` (bin√°rio: yes/no)
- Features: Todas as demais vari√°veis

### 3. Verifica√ß√£o de Tipos

Orange detecta automaticamente os tipos de dados:
- Num√©ricos: account_age_weeks, data_usage_gb, customer_service_calls, day_minutes, day_calls, monthly_charge, overage_fee, roam_minutes
- Categ√≥ricos: contract_renewal, data_plan
- Target: churn (categ√≥rico bin√°rio)

### 4. Split Treino/Teste

**Widget utilizado:** Data Sampler

**Configura√ß√£o:**
- **Treino:** 80% (utilizado para valida√ß√£o cruzada)
- **Teste:** 20% (hold-out set, n√£o tocado at√© valida√ß√£o final)
- **M√©todo:** Random sampling
- **Stratified:** Ativado (mant√©m propor√ß√£o de classes)
- **Replicable:** Seed fixada para reprodutibilidade

**Justificativa do split 80/20:**
- Padr√£o da ind√∫stria para datasets de tamanho m√©dio
- Balan√ßa quantidade de dados para treino vs. confiabilidade do teste
- Permite valida√ß√£o cruzada robusta no conjunto de treino

---

## An√°lise Explorat√≥ria

### Hip√≥teses Iniciais

Antes da modelagem, foram levantadas hip√≥teses sobre a import√¢ncia de cada vari√°vel para prever churn, atribuindo notas de 0 (irrelevante) a 100 (muito importante).

**Crit√©rios para atribui√ß√£o de notas:**
1. L√≥gica de neg√≥cio (experi√™ncia em gest√£o)
2. Literatura sobre churn em telecomunica√ß√µes
3. Intui√ß√£o sobre comportamento do consumidor

**Resultado:** Documentado em `data/hipoteses_iniciais.xlsx`

### Objetivo da An√°lise Pr√©via

- Exercitar pensamento cr√≠tico antes de ver os dados
- Validar posteriormente se as hip√≥teses estavam corretas
- Demonstrar compreens√£o do dom√≠nio do problema

---

## Sele√ß√£o de Modelos

### Valida√ß√£o Cruzada

**Widget utilizado:** Test & Score

**Configura√ß√£o:**
- **M√©todo:** Cross-validation (k-fold)
- **K:** 10 folds
- **Stratified:** Ativado
- **Shuffle:** Ativado

**Por que k=10?**
- Balan√ßa vi√©s vs. vari√¢ncia
- Padr√£o amplamente aceito na literatura
- Usa 90% dos dados para treino em cada fold

### Algoritmos Testados

#### 1. Logistic Regression (4 modelos)

**Widget:** Logistic Regression

**Varia√ß√µes testadas:**
- **Lasso (C=0.1):** Regulariza√ß√£o forte
- **Lasso (C=1.0):** Regulariza√ß√£o moderada
- **Ridge (C=0.1):** Regulariza√ß√£o forte
- **Ridge (C=1.0):** Regulariza√ß√£o moderada

**Justificativa:**
- Baseline simples e interpret√°vel
- Testou diferentes n√≠veis de regulariza√ß√£o
- Compara√ß√£o Lasso (L1) vs Ridge (L2)

#### 2. Random Forest (4 modelos)

**Widget:** Random Forest

**Varia√ß√µes testadas:**
- **RF (300 trees, max_features=4)**
- **RF (300 trees, max_features=3)** ‚Üê **Modelo vencedor**
- **RF (100 trees, max_features=4)**
- **RF (100 trees, max_features=3)**

**Hiperpar√¢metros fixos:**
- min_samples_split: 2 (padr√£o)
- min_samples_leaf: 1 (padr√£o)
- bootstrap: True

**Justificativa:**
- Variou n√∫mero de √°rvores (100 vs 300)
- Variou max_features (~1/3 das features, conforme recomendado)
- Mais √°rvores = maior estabilidade (mas computacionalmente mais caro)

#### 3. Gradient Boosting Machine (4 modelos)

**Widget:** Gradient Boosting

**Varia√ß√µes testadas:**
- **GBM (50 trees)**
- **GBM (100 trees)**
- **GBM (200 trees)**
- **GBM (300 trees)**

**Hiperpar√¢metros fixos:**
- learning_rate: 0.1 (padr√£o)
- max_depth: 3 (padr√£o)

**Justificativa:**
- Fixou outros par√¢metros para isolar efeito do n√∫mero de √°rvores
- GBM geralmente requer menos √°rvores que RF

#### 4. Neural Networks (4 modelos)

**Widget:** Neural Network

**Varia√ß√µes testadas:**
- **NN (50 neurons, 200 iterations)**
- **NN (50 neurons, 400 iterations)**
- **NN (100 neurons, 200 iterations)**
- **NN (100 neurons, 400 iterations)**

**Hiperpar√¢metros fixos:**
- Hidden layers: 1 camada
- Activation: ReLU
- Solver: Adam

**Justificativa:**
- Variou complexidade (neur√¥nios) e tempo de treino (itera√ß√µes)
- Manteve arquitetura simples (1 camada) para facilitar interpreta√ß√£o

### M√©tricas de Avalia√ß√£o

**M√©tricas utilizadas:**
- **AUC-ROC:** M√©trica principal (robusta a desbalanceamento)
- **Accuracy:** Performance geral
- **F1-Score:** Balan√ßa Precision e Recall
- **Precision:** Quantos churns previstos eram realmente churn
- **Recall:** Quantos churns reais foram identificados
- **MCC:** Matthews Correlation Coefficient (leva em conta todas as c√©lulas da matriz de confus√£o)

**Por que AUC como m√©trica principal?**
- Invariante a threshold de classifica√ß√£o
- Robusta a desbalanceamento de classes
- Amplamente utilizada em problemas de churn

### Crit√©rios de Sele√ß√£o

**Modelo escolhido:** Random Forest (300 trees, max_features=3)

**Crit√©rios:**
1. **AUC:** 0.905 (empatado com GBM-100 no topo)
2. **MCC:** 0.737 (superior ao GBM-100 que tinha 0.723)
3. **Estabilidade:** 300 √°rvores oferecem mais robustez que 100
4. **Interpretabilidade:** RF √© mais f√°cil de explicar que GBM
5. **Adequa√ß√£o para produ√ß√£o:** Menor risco de overfitting

**Trade-off reconhecido:**
- RF (100 trees, 3 feats) tinha F1 e MCC ligeiramente superiores
- Decis√£o priorizou estabilidade para ambiente de produ√ß√£o

---

## Valida√ß√£o Final

### Teste em Hold-out Set

**Widget utilizado:** Predictions

**Procedimento:**
1. Treinar modelo vencedor com 100% do conjunto de treino (80% dos dados originais)
2. Aplicar modelo no conjunto de teste (20% nunca visto)
3. Avaliar m√©tricas

### An√°lise de Overfitting

**Compara√ß√£o:**

| M√©trica | Cross-Val | Teste | Varia√ß√£o |
|---------|-----------|-------|----------|
| AUC | 0.905 | 0.880 | -2.8% |
| Accuracy | 93.9% | 92.3% | -1.7% |
| F1-Score | 0.936 | 0.919 | -1.8% |
| MCC | 0.737 | 0.667 | -9.5% |

**Interpreta√ß√£o:**
- Queda de AUC < 3% √© considerada aceit√°vel
- Todas as m√©tricas permaneceram acima de 90% (exceto MCC)
- **Conclus√£o:** Modelo generaliza bem, sem overfitting significativo

---

## Interpretabilidade

### Permutation Feature Importance

**Widget utilizado:** Feature Importance (extens√£o Explain)

**M√©todo:**
- Permutation Importance baseado em AUC
- Permuta aleatoriamente cada feature e mede queda no AUC
- Quanto maior a queda, mais importante a feature

**Configura√ß√£o:**
- Score: AUC
- Permutations: 20 (padr√£o)
- Top features: 10 (todas as features)

### Compara√ß√£o: Expectativa vs. Realidade

**Resultado:**
- **100% de alinhamento** nas 3 principais vari√°veis
- Top 3 esperado: monthly_charge, customer_service_calls, contract_renewal
- Top 3 real: monthly_charge, customer_service_calls, contract_renewal

**Insights:**
1. A an√°lise conceitual estava correta
2. Pre√ßo (monthly_charge) √© o fator mais determinante
3. Insatisfa√ß√£o (customer_service_calls) √© forte preditor
4. Compromisso (contract_renewal) confirma inten√ß√£o de perman√™ncia

---

## Deploy Simulado

### Previs√£o para Novo Cliente

**Dados de entrada:**
```python
{
    'account_age_weeks': 128,
    'contract_renewal': 1 (yes),
    'data_plan': 0 (no),
    'data_usage_gb': 0.0,
    'customer_service_calls': 4,
    'day_minutes': 265.1,
    'day_calls': 110,
    'monthly_charge': 45.0,
    'overage_fee': 10.5,
    'roam_minutes': 14.2
}
```

**Resultado:**
- Classe prevista: **N√ÉO CHURN**
- Probabilidade de perman√™ncia: **53%**
- Probabilidade de churn: **47%**

### An√°lise de Caso Lim√≠trofe

Este cliente est√° na **fronteira de decis√£o** do modelo:
- Diferen√ßa de apenas 6 pontos percentuais
- Representa incerteza do modelo
- Requer aten√ß√£o especial em produ√ß√£o

**Recomenda√ß√£o de neg√≥cio:**
- Monitoramento pr√≥ximo
- A√ß√£o preventiva recomendada
- Incluir em programa de reten√ß√£o

---

## Considera√ß√µes Finais

### Pontos Fortes da Metodologia

1. ‚úÖ Valida√ß√£o cruzada estratificada (k=10)
2. ‚úÖ Hold-out set preservado at√© o fim
3. ‚úÖ M√∫ltiplos algoritmos testados (16+ configura√ß√µes)
4. ‚úÖ Hiperpar√¢metros variados sistematicamente
5. ‚úÖ Interpretabilidade com Permutation Importance
6. ‚úÖ An√°lise de casos lim√≠trofes

### Limita√ß√µes Reconhecidas

1. ‚ö†Ô∏è Ferramenta no-code (limita√ß√µes de customiza√ß√£o)
2. ‚ö†Ô∏è Dataset acad√™mico (pode n√£o refletir complexidade real)
3. ‚ö†Ô∏è N√£o testou t√©cnicas de balanceamento (SMOTE, etc.)
4. ‚ö†Ô∏è N√£o realizou feature engineering avan√ßado
5. ‚ö†Ô∏è N√£o avaliou impacto de diferentes thresholds

### Pr√≥ximos Passos para Aprofundamento

- [ ] Reimplementar em Python (scikit-learn)
- [ ] Experimentar feature engineering
- [ ] Testar t√©cnicas de balanceamento de classes
- [ ] An√°lise de curva Precision-Recall
- [ ] Otimiza√ß√£o de threshold para neg√≥cio

---

## Refer√™ncias Metodol√≥gicas

1. **Cross-Validation:**
   - Kohavi, R. (1995). "A study of cross-validation and bootstrap for accuracy estimation and model selection"

2. **Random Forest:**
   - Breiman, L. (2001). "Random Forests". Machine Learning, 45(1), 5-32.

3. **Permutation Importance:**
   - Breiman, L. (2001). "Random forests". Machine Learning, 45(1), 5-32.

4. **Model Evaluation:**
   - Davis, J., & Goadrich, M. (2006). "The relationship between Precision-Recall and ROC curves"

5. **Churn Prediction:**
   - Hadden, J., et al. (2007). "Computer assisted customer churn management: State-of-the-art and future trends"

---

*Documenta√ß√£o elaborada como parte do projeto acad√™mico de Fundamentos de Machine Learning - MBA SENAC-RJ (2026)*
